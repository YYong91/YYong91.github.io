---
title: "🚀 ActiveMQ → RabbitMQ 전환기"
date: 2025-11-23
categories: ["infra"]
tags: ["AMQP", "ActiveMQ", "Amazon MQ", "DLQ", "Dead Letter Queue", "Lazy Queue", "MQ", "Message Queue", "aws", "rabbitmq", "마이그레이션", "메시지 브로커"]
migrated_from: "velog"
---

## 0. 소개

저희 팀은 수년간 ActiveMQ 기반 메시징 시스템을 운영해 왔습니다. 상품, 가격, 이미지, 옵션, 주문 등 여러 마이크로서비스가 비동기 메시지로 연결된 구조였고, 하루 수십만~수백만 건의 메시지를 처리하는 환경에서 **메시지 브로커의 안정성은 시스템 전체 품질을 좌우하는 핵심 요소**였습니다.

AWS에서 RabbitMQ를 공식 지원하기 시작한 시점을 계기로 ActiveMQ에서 RabbitMQ로의 전환을 결정했고, 실제 운영 환경에서 **메시징 구조가 어떻게 바뀌었는지**, **왜 교체를 결심했는지**, **전환 과정은 어떻게 진행되었는지**를 이 글에서 정리합니다.

---

## 1. 왜 처음엔 ActiveMQ를 사용했는가

### 1.1 당시 선택지가 제한적이었던 AWS 환경

마이크로서비스 구조가 설계되던 당시 AWS의 Amazon MQ는 ActiveMQ만 공식 지원하고 있었습니다. RabbitMQ는 AWS Managed 서비스가 아니었기 때문에 선택지에 포함될 수 없었습니다.

### 1.2 서비스 구조적 요구

상품 변경이 가격·옵션·이미지 서비스로 연속적인 이벤트를 발생시키는 구조였고, 비동기 메시징은 필수였습니다. 따라서 Managed MQ 기반의 ActiveMQ 도입은 자연스러운 선택이었습니다.

---

## 2. ActiveMQ 사용 중 겪은 실제 문제점

### 2.1 운영 자동화의 어려움

ActiveMQ Classic은 웹 콘솔 중심 구조이며 API 기반 관리가 제한적입니다. 실제 운영에서 다음과 같은 문제들이 발생했습니다.

* **큐 적체량 자동 모니터링 어려움**
  예: 가격 서비스에서 일시적으로 메시지가 폭증하면 큐가 빠르게 10만 건 이상 적체되곤 했습니다. 하지만 ActiveMQ는 큐 적체량을 이벤트 기반으로 감지하거나 Alert을 자동화하기 어렵기 때문에, 운영자가 콘솔을 보지 않으면 적체를 즉시 발견할 수 없었습니다. 결국 장애 인지가 늦어지는 경우가 잦았습니다.

* **큐 상태를 코드 기반으로 파악하기 어려움**
  예: 운영팀에서 자동화 도구(minions)용으로 "큐별 메시지 수 조회", "top 적체 서비스 진단" 같은 기능을 개발하고 싶었지만 ActiveMQ에서는 API 접근성이 낮아 사실상 만들 수 없었습니다. JMX 경로를 통해 정보를 가져올 수는 있지만, 언어 의존성(Python 환경 부적합), 구조 복잡성 때문에 실서비스 자동화에는 사용할 수 없었습니다.

이런 제한 때문에 ActiveMQ에서는 운영자가 직접 콘솔에 들어가 확인하고 조치하는 일이 많았고, 운영 효율이 자연스럽게 떨어질 수밖에 없었습니다.

### 2.2 관리 작업의 수동성

다음 작업 대부분을 사람이 직접 클릭으로 수행해야 했습니다.

* purge
* 큐 삭제
* DLQ 재처리

운영 규모가 커질수록 장애 대응 속도가 크게 떨어지고 유지보수 비용이 증가했습니다.

### 2.3 구조·성능적 한계

* **JVM 기반이라 메시지가 쌓일수록 GC 부담 증가**
  JVM 위에서 동작하기 때문에 메시지가 많아지면 메모리에 객체가 누적되고, GC가 자주 돌며 브로커 전체 처리 속도가 느려질 수 있습니다.

* **대량 적체 시 성능 저하 심각**
  ActiveMQ는 메모리 의존도가 높아 큐가 길어질수록 처리 성능이 급격히 떨어지고, 적체가 계속되면 브로커가 불안정해지는 문제가 발생합니다.

* **slow consumer가 전체 지연에 영향**
  한 consumer가 느리면 해당 큐 전체 처리 속도가 함께 늦어지는 구조적 특징이 있어 전체 latency가 증가할 수 있습니다.

* **메시지 순서 보장 불안정**
  재전송, 적체 상황 등 특정 조건에서 out-of-order가 발생하기 쉬워, 순서 민감한 서비스에서는 별도 보완 로직이 필요합니다.

* **브로커 관측 지표 부족**
  처리량, 메시지 체류 시간, 재전송 횟수 등 운영 의사결정에 필요한 지표가 즉시적으로 제공되지 않아 모니터링·Alerting 체계를 고도화하기 어렵습니다.

### 2.4 자동화의 실질적 제한 (JMX/Jolokia)

HTTP API 사용을 위해 Jolokia( JMX 데이터를 HTTP로 변환하는 브리지 )를 붙일 수 있으나:

* 기능 부족
* Python 환경에서 다루기 불편
* 자동화 도구 제작 난이도 매우 높음

---

## 3. RabbitMQ를 고려하게 된 계기

ActiveMQ를 쓴다고 해서 당장 서비스가 망가지는 것은 아니었고, 오랫동안 큰 장애 없이 운영해 온 것도 사실입니다. 다만 2장에서 정리한 것처럼, 시간이 지날수록 다음과 같은 피로도가 조금씩 쌓이고 있었습니다.

* 큐 적체 상황을 **자동으로 감지·알림 보내는 체계**를 만들기 어렵다는 점
* 운영자가 **콘솔에 직접 들어가서 확인·조치해야 하는 작업**이 많다는 점
* 브로커 내부 상태를 **코드 기반(minions 등)으로 조회·가시화하기 힘들다**는 점

즉, "지금 당장 망가지진 않지만, 이 구조 위에서 더 스케일업하는 것은 부담스럽다"는 인식이 팀 내에 서서히 생기고 있었습니다.

이런 상황에서 **AWS가 RabbitMQ를 Amazon MQ의 한 옵션으로 공식 지원**하기 시작했고, 이를 계기로 본격적으로 대안을 검토하게 되었습니다. "어차피 MQ를 더 오래 가져가야 한다면, 지금 시점에 한 번 구조를 갈아타는 것이 장기적으로 낫지 않을까?" 하는 논의가 자연스럽게 나왔습니다.

그때 우리가 중점적으로 본 기준은 대략 다음과 같았습니다.

* 운영 자동화: HTTP API, 모니터링, Alerting, 내부 CLI(minions) 연동 용이성
* 확장성: 트래픽 증가·서비스 증가 시 구조적으로 버틸 수 있는지
* 안정성: 적체·장애 상황에서 브로커가 어떻게 실패하고, 얼마나 예측 가능한지
* 학습·도입 비용: 기존 서비스 코드 변경 범위, 메시지 스키마 재사용 가능 여부

RabbitMQ는 이 기준에서 ActiveMQ 대비 여러 장점이 있었고, 특히 **운영 자동화·확장성 측면에서 "앞으로 더 성장할 여지가 많은 브로커"**라고 판단했습니다. 이 판단이 이후 4장에서 정리한 선택 이유와 마이그레이션 전략의 기반이 되었습니다.

---

## 4. RabbitMQ를 선택한 이유

### 4.1 AMQP 기반 메시징 모델의 유연함

#### (실제 운영에서는 어떻게 느껴졌는가?)

ActiveMQ에서도 Topic 기반 fanout 구조를 잘 사용해 왔기 때문에 처음에는 "RabbitMQ의 Exchange 모델이 꼭 더 우수하다"는 느낌은 크지 않았습니다. 실제로 우리가 쓰던 메시징 패턴은 비교적 단순했고, 두 브로커 모두 유사하게 구현할 수 있었습니다.

그러나 **RabbitMQ의 Exchange → Queue 바인딩 모델은 구조적 확장성에서 확실한 차이**를 만들어냈습니다. 서비스가 늘어나거나 이벤트 라우팅 패턴이 복잡해질수록, Exchange 단에서 라우팅을 세밀하게 제어할 수 있다는 점이 점점 더 중요한 장점으로 느껴졌습니다.

우리 팀이 이 전환에서 중요하게 본 포인트는 다음과 같았습니다.

* 지금은 단순한 메시징만 쓰더라도,
* **서비스·트래픽·이벤트 패턴이 늘어나면 RabbitMQ가 제공하는 라우팅 옵션이 훨씬 유연한 선택지를 제공한다는 점**
* 확장 시에도 기존 구조를 크게 바꾸지 않고 새로운 서비스나 라우팅 규칙을 추가할 수 있다는 점

즉, RabbitMQ는 처음에는 ActiveMQ와 '비슷하게' 사용할 수 있지만, **장기적으로 구조적 성장 여력이 훨씬 큰 브로커**라고 판단했습니다. 이 점이 우리가 RabbitMQ를 선택한 중요한 이유였습니다.

> 결론적으로, RabbitMQ는 AMQP 기반 구조 덕분에 **서비스 증가·이벤트 흐름 복잡화·트래픽 확장**을 자연스럽게 수용할 수 있는 유연한 메시징 모델을 제공합니다.

### 4.2 DLX 기반 Dead Letter 관리

ActiveMQ에서도 우리는 큐별로 대응되는 DLQ를 만들어 **문제 서비스별로 실패 메시지를 분리**해두었기 때문에 운영 자체는 충분히 안정적으로 이뤄졌습니다. 다만 이 구조를 만들기 위해서는:

* 브로커 정책(PolicyEntry) 설정,
* deadLetterStrategy 조정,
* XML 기반 설정 수정,
* 일부 설정 적용 시 브로커 재시작,

같은 작업이 필요했고, **정책의 위치가 브로커 전역 단위에 있어 유지보수 난이도가 높았습니다**. 즉, 결과적으로는 잘 동작했지만 "ActiveMQ의 기본 구조가 간단했다"기보다는 **우리가 직접 세심하게 설계하고 관리해온 커스텀 구조**에 가까웠습니다.

반면 RabbitMQ는 DLQ가 **브로커 정책이 아니라 큐 자체의 속성으로 자연스럽게 포함**됩니다. 즉, ActiveMQ에서 정책으로 구현했던 동작을 RabbitMQ에서는 **큐 생성 시 몇 줄의 속성만으로** 구성할 수 있습니다.

#### (RabbitMQ에서 DLX/DLQ 설정 예시)

```json
{
  "x-dead-letter-exchange": "service.dlx",
  "x-dead-letter-routing-key": "service.dlq"
}
```

이 두 줄만 설정하면 다음 흐름이 자동으로 작동합니다:

1. 메시지가 처리 중 예외(Nack, Reject), TTL 만료, 재시도 초과 등으로 실패하면,
2. 해당 큐의 DLX 설정을 기반으로 RabbitMQ가 자동으로 DLX로 메시지를 이동시키고,
3. DLX는 바인딩된 DLQ로 메시지를 라우팅합니다.

그 결과 실패 메시지는 항상 우리가 지정한 **서비스 단위 DLQ로 예측 가능하게 쌓이며**, 메시지에는 `x-death` 헤더가 자동으로 추가되어 **실패 원인·횟수·처리 이력까지 추적 가능**합니다.

#### (왜 RabbitMQ의 DLX 구조가 ActiveMQ보다 운영상 유리한가?)

* ActiveMQ: 큐별 DLQ 분리를 위해 브로커 정책을 수정해야 함 → **RabbitMQ는 큐 속성만 설정하면 됨**
* ActiveMQ: deadLetterStrategy 동작이 설정마다 달라 테스트 필요 → **RabbitMQ는 DLX 규칙이 일관적으로 동작**
* ActiveMQ: 실패 원인 추적 정보가 제한적 → **RabbitMQ는 x-death 헤더에 자동 기록**
* ActiveMQ: DLQ 복구 자동화가 상대적으로 어려움 → **RabbitMQ는 Shovel/HTTP API 기반 자동화가 매우 쉽다**

요약하면,

> ActiveMQ에서도 DLQ 구조를 잘 만들어 운영해왔지만, RabbitMQ는 같은 구조를 훨씬 단순하고 일관적인 방식으로 기본 지원해 운영 난이도를 크게 낮춰준다.

### 4.3 Lazy Queue 기반 브로커 안정성 향상

RabbitMQ는 메시지를 메모리에만 보관하는 것이 아니라 **가능한 한 디스크로 오프로드하여 적체 상황에서도 브로커 전체 안정성을 유지하는 구조**를 제공합니다. 그 핵심이 **Lazy Queue**입니다.

#### ✔ Lazy Queue

Lazy Queue는 **메시지를 기본적으로 디스크에 저장하고, 소비 직전에만 메모리로 가져오는 큐 모드**입니다. 이 기능은 ActiveMQ Classic에는 존재하지 않는 RabbitMQ 고유의 처리 방식입니다.

ActiveMQ는 JVM 위에서 동작하기 때문에 메시지가 메모리에 누적되면 GC 영향으로 브로커 전체 성능이 저하될 수 있습니다. 반면 RabbitMQ Lazy Queue는 적체 상황에서도 메모리 사용량이 크게 증가하지 않아 **GC 부담, 메모리 압박, 브로커 전체 지연 증가 같은 문제가 발생하지 않습니다.**

Lazy Queue의 주요 효과는 다음과 같습니다.

* 대량 적체 상황에서도 메모리 기반 병목 없이 안정적입니다.
* 메시지가 수십만 건 이상 쌓여도 브로커가 급격히 느려지지 않습니다.
* 적체 자체가 장애로 이어지지 않아 운영자가 부담 없이 backlog를 처리할 수 있습니다.
* ActiveMQ에서 흔히 보던 "적체 → 브로커 전체 지연 → 재시작 고려" 패턴이 사라집니다.

우리도 Lazy Queue를 주요 큐에 적용해, **트래픽 폭증 시에도 브로커가 안정적으로 버티는 경험**을 했습니다.

> 정리하면, Lazy Queue는 ActiveMQ에는 없는 구조적 장점이며, 대규모 적체 환경에서 RabbitMQ의 안정성을 크게 높여준 기능입니다.

### 4.4 운영 자동화에 최적화된 HTTP API

RabbitMQ는 HTTP API를 통해 브로커의 거의 모든 상태를 **JSON 형태로 직접 조회·제어**할 수 있습니다. 이는 ActiveMQ의 JMX 기반 구조와 비교했을 때 운영 자동화 측면에서 큰 강점입니다.

RabbitMQ HTTP API의 특징은 다음과 같습니다.

* **언어 제약 없이(Python·Go 등) 운영 도구 개발 가능**
* **큐 상태, 메시지 수, 바인딩 정보, consumer 상태, DLQ 상태를 모두 API로 조회 가능**
* **메시지 재전송·이관·삭제 같은 관리 기능도 API 기반으로 처리 가능**
* 운영 중에도 API 호출만으로 상태를 즉시 확인할 수 있어 Alerting·자동화 흐름 구축이 용이합니다.

우리 팀 역시 HTTP API를 활용해 내부 운영 CLI(minions)를 구축했습니다. 이를 통해 다음과 같은 기능을 자동화했습니다.

* queue pending 조회
* DLQ pending 조회
* DLQ → 정상 큐 복구 수행 (키워드 기반)

DLQ 복구는 상황에 따라 **API 기반 재삽입 방식**과 **Shovel을 통한 자동 이관**을 병행했습니다. 단순 소량 복구는 API로 처리했고, 대량 적체가 발생한 경우에는 Shovel을 적용해 자동 이관 흐름을 구성하는 방식이었습니다.

이러한 HTTP API 기반 자동화 덕분에 ActiveMQ에서 흔했던 "콘솔 접속 → 수동 확인 → 수동 조치" 패턴이 사라지고, 운영 안정성과 대응 속도가 크게 향상되었습니다.

### 4.5 플러그인 생태계 (참고용)

RabbitMQ는 다양한 플러그인을 제공하지만, 우리 팀이 실서비스에서 모두 사용한 것은 아닙니다. 다만 확장성과 운영 자동화 측면에서 어떤 선택지가 있는지 참고용으로 정리하면 다음과 같습니다.

* **Shovel**: 브로커 간 메시지 이관 또는 DLQ → 정상 큐 자동 이동에 활용할 수 있는 플러그인입니다. 우리도 대량 메시지 복구 자동화를 구성할 때 참고했습니다.
* **Federation**: 여러 RabbitMQ 브로커를 느슨하게 연결할 수 있어 멀티 리전 또는 서비스별 브로커를 구성할 때 유용합니다.
* **Prometheus Exporter**: 메시지 적체량, 처리량, consumer 상태 등 운영 지표를 실시간으로 수집할 수 있어 모니터링 품질을 높이는 데 도움이 됩니다.
* **Management UI**: 직관적인 관리 화면을 통해 라우팅, 큐 상태, consumer 상태 등을 쉽게 파악할 수 있습니다.

> 해당 플러그인들은 "향후 확장성 확보를 위한 옵션"으로 참고용으로 정리한 것이며, 모든 기능을 실서비스에서 직접 활용한 것은 아닙니다.

---

## 5. 실제 마이그레이션 과정

ActiveMQ → RabbitMQ 전환은 단순히 브로커만 바꾸는 작업이 아니라, **서비스 간 이벤트 흐름 전체를 다시 검증하고 안정성을 확보하는 과정**이었습니다. 특히 하루 수십만 건 이상의 메시지를 처리하는 구조였기 때문에, "중단 없이 자연스럽게 전환되는 것"이 핵심 목표였습니다.

아래는 우리가 실제로 수행한 마이그레이션 단계와 그 이유, 검증 포인트들입니다.

### 5.1 Dual Publish 방식으로 시작

초기에는 **ActiveMQ와 RabbitMQ에 동시에 메시지를 발행(Dual Publish)** 하여 RabbitMQ 환경을 병렬로 검증했습니다. 기존 ActiveMQ 소비 흐름을 유지하면서 RabbitMQ consumer를 shadow 모드로 두고 다음을 확인했습니다.

* 메시지 유실 여부
* 순서 보장 여부
* 처리 latency 비교
* DLX 라우팅 정상 작동
* prefetch 값 변화에 따른 consumer 처리량 변화
* payload 크기·특수 케이스 처리

Dual Publish는 서비스 중단 없이 전환을 시도할 수 있는 가장 안전한 방식이었으며, 예상하지 못한 edge-case를 발견하는 데 큰 도움이 되었습니다.

### 5.2 Idempotency(중복 처리) 적용

Dual Publish 기간 동안 동일 이벤트가 두 브로커에 동시에 쌓이므로, 메시지 소비가 중복될 가능성이 있었습니다. 이를 위해 **모든 consumer에 idempotency 정책**을 적용했습니다.

이 단계에서 idempotency 구조가 정립되면서 이후 재처리·DLQ 복구 시에도 안정성을 확보할 수 있는 기반이 되었습니다.

### 5.3 서비스 단위 점진적 전환

충분히 검증된 뒤 **서비스 단위로 RabbitMQ 소비를 실제 처리에 투입**했습니다.

1. RabbitMQ consumer를 실제 처리 흐름에 연결
2. ActiveMQ consumer 비활성화
3. 안정화 후 ActiveMQ 발행 제거

이 순서를 사용한 이유는 다음과 같습니다.

* 메시지 흐름이 RabbitMQ에서도 그대로 유지되는지 확인
* 서비스별 특수 로직(순서 의존, locking, bulk update 등) 검증
* 문제 발생 시 빠르게 ActiveMQ 소비를 복원할 수 있는 여지 확보

충격도가 낮은 서비스부터 시작해 핵심 서비스로 확장하는 방식으로 전환 부담을 최소화했습니다.

### 5.4 메시지 스키마 변경 없음

전환 비용을 최소화하기 위해 기존 JSON 메시지 스키마를 그대로 유지했습니다. 덕분에 서비스 코드 변경 범위를 최소화할 수 있었고, 검증 범위도 줄어들어 서비스별 전환 속도를 빠르게 가져갈 수 있었습니다.

---

## 6. ActiveMQ Classic vs RabbitMQ 비교표

| 구분 | ActiveMQ Classic | RabbitMQ |
| --- | --- | --- |
| 프로토콜 | JMS API + OpenWire 프로토콜 | AMQP 0.9.1 |
| 메시징 모델 | Queue/Topic 중심 | Exchange → Queue 라우팅 구조 |
| Dead Letter 처리 | 브로커 정책 기반, 설정 복잡 | DLX 기반 자동 라우팅, 일관적 동작 |
| 대량 메시지 처리 | JVM 기반, 적체 시 성능 급저하 | Lazy Queue로 안정적 디스크 오프로드 |
| 재시도(redelivery) | 브로커 자동 재시도 → 예측 어려움 | 소비자에서 명시적 구현 → 흐름 명확 |
| 메시지 순서 보장 | 재전송/적체 상황에서 순서 깨질 수 있음 | 큐 단위 FIFO가 안정적으로 유지됨 |
| 저장 구조 | KahaDB 중심, 메모리 의존 높음 | 디스크 중심 + 메모리 캐시 구조 |
| 스케일아웃/클러스터링 | 네트워크 브릿지 기반, 확장 어려움 | Erlang 기반 클러스터 → 확장 용이 |
| 모니터링 | JMX 기반, 지표 제한적 | Prometheus Exporter로 풍부한 지표 제공 |
| 운영 자동화 | 사실상 불가능(JMX/Jolokia 의존) | REST API로 완전 자동화 가능 |
| 플러그인 | 제한적 | Shovel/Federation 등 다양 |
| 관리 도구 | 웹 콘솔 중심 | CLI/HTTP API 모두 지원 |

---

## 7. RabbitMQ 도입 후 개선된 점

### 7.1 운영 자동화 구축(minions CLI)

RabbitMQ HTTP API 기반으로 내부 CLI 도구를 구축하면서 운영 효율이 크게 향상되었습니다. 이전에는 콘솔에 접속해 수동으로 처리해야 했던 작업들을 명령 한 번으로 수행할 수 있게 되었고, 장애 대응 속도도 체감될 정도로 빨라졌습니다.

* queue pending 조회 자동화
* DLQ pending 조회 자동화
* DLQ → 정상 큐 복구 기능 제공
* 반복적 운영 작업의 표준화·자동화

### 7.2 DLQ 복구 흐름 간소화

RabbitMQ의 DLX 구조 덕분에 실패 메시지가 서비스 단위 DLQ로 일관되게 쌓이게 되었고, 이를 기반으로 **API 기반 복구** 또는 **Shovel 기반 이관**을 상황에 따라 선택적으로 적용할 수 있었습니다. 덕분에 ActiveMQ 대비 복구 절차가 단순해지고, 원인 분석 시간도 줄어들었습니다.

### 7.3 메시지 처리 안정성 개선

RabbitMQ 전환 이후 ActiveMQ에서 자주 발생하던 문제들이 크게 줄어들었습니다.

* consumer 멈춤 현상 감소
* 대량 적체 시 브로커 전체 지연 문제 해소
* DLQ 원인 파악 용이(x-death 헤더)
* Lazy Queue 적용으로 트래픽 급증 상황에서도 안정성 확보

이러한 개선 덕분에 메시징 기반 서비스 전반의 신뢰도가 높아졌으며, 운영 부담도 크게 감소했습니다.

---

## 8. 마이그레이션을 통해 배운 점

ActiveMQ → RabbitMQ 전환은 단순한 브로커 교체 작업이 아니라, **서비스 전반의 메시징 구조를 다시 점검하고 운영 품질을 근본적으로 끌어올리는 과정**이었습니다. 이 과정에서 다음과 같은 중요한 인사이트를 얻었습니다.

### 8.1 메시징 전환은 "기술 교체"가 아니라 "흐름 재정비"이다

브로커만 바뀌는 것처럼 보이지만, 실제로는 서비스 간 이벤트 흐름, 처리 순서, 예외 상황 대응 방식까지 모두 점검하는 작업이었습니다. 이를 통해 기존 시스템에서 보이지 않았던 개선 여지를 여러 곳에서 발견할 수 있었습니다.

### 8.2 DLQ 설계는 메시징 시스템의 핵심이다

ActiveMQ 시절에도 큐별 DLQ를 잘 만들어 운영해왔지만, RabbitMQ 전환 과정에서 DLX 기반 일관 구조의 가치를 다시 한 번 체감했습니다. 실패 흐름이 명확할수록 운영 자동화가 쉬워지고, 장애 대응 속도와 품질도 높아집니다.

### 8.3 운영 자동화는 "선택"이 아니라 "기반"이다

RabbitMQ HTTP API 기반 자동화를 적용하면서 운영 효율이 극적으로 향상되었습니다. 메시징 시스템은 운영이 잦기 때문에, 자동화 기반을 갖추는 것이 전체 신뢰도를 높이는 지름길이라는 점을 명확히 배웠습니다.

### 8.4 브로커 성능은 구조에서 결정된다

Lazy Queue, DLX, Exchange 모델 등은 단순 기능이 아니라, 브로커가 대규모 트래픽을 어떻게 견디는지를 결정하는 구조적 요소였습니다. 결국 구조적인 우월성이 장기 운영 품질에 가장 큰 차이를 만든다는 것을 확인했습니다.

---

## 🏁 결론

RabbitMQ 전환은 단순히 "더 좋은 브로커로 갈아탄 것"이 아니라,
**대규모 메시징 기반 마이크로서비스 운영 환경에서 안정성·자동화·확장성을 한 단계 끌어올린 결정**이었습니다.

* 운영 자동화 수준 향상
* DLQ 흐름의 단순화·명확화
* 적체·트래픽 증가 상황에서도 안정적인 브로커 성능
* 서비스별 메시징 흐름 재정비로 인한 구조적 개선

이 네 가지는 특히 큰 효과를 가져왔습니다.

지금도 메시징 패턴은 계속 진화하고 있고, 서비스 규모도 커지고 있습니다. 그 과정에서 RabbitMQ의 구조적 유연함과 운영 친화성은 앞으로도 큰 기반이 될 것이라 생각합니다.

전환을 고민하는 팀이라면, 단순한 브로커 비교를 넘어 **자신들의 메시징 흐름 전체를 다시 한 번 점검해보는 계기**로 삼아보시기를 적극 추천드립니다.
